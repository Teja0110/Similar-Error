{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Nescessary Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import json to read a json file\n",
    "import json\n",
    "import data_utils as dt #Read Json file and create diction of text and markup\n",
    "import string\n",
    "import math\n",
    "import nltk\n",
    "from difflib import SequenceMatcher \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data is a list of dictionaries of text and its markup\n",
    "data = dt.process_data('Data/tai-documents-v3/tai-documents-v3.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A example of markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]['markup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process each essay and find similar error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input: and essay with plain_text and markup\n",
    "# output: return a list of similar errors of word_choice with number of error for each\n",
    "# The related words for that error and the indices (on markup) of that error\n",
    "def word_choice(input):\n",
    "    output = []\n",
    "    check = False\n",
    "    for i in range(len(input['markup'])):\n",
    "        error = input['markup'][i]\n",
    "        check = False\n",
    "        if error['type'] == 'word choice':\n",
    "            # Check if we see this error before, update the error_count\n",
    "            for item in output:\n",
    "                if ((error['old_text'] in item['words']) or\n",
    "                   (error['new_text'] in item['words'])):\n",
    "                        check = True # Set this error already marked\n",
    "                        item['index'].append(i)                          \n",
    "                        item['words'].add(error['old_text'])\n",
    "                        if error['new_text'] != None and error['new_text'] != '':\n",
    "                            item['words'].add(error['new_text'])\n",
    "                        item['error_count'] = item['error_count'] + 1\n",
    "            \n",
    "            # The error haven't been seen before\n",
    "            if check == False:\n",
    "                if error['new_text'] != None: \n",
    "                    output.append({'words' : {error['old_text'], error['new_text']}, \n",
    "                               'index' : [i], 'error_count' : 1})\n",
    "                else: \n",
    "                    output.append({'words' : {error['old_text']}, \n",
    "                               'index' : [i], 'error_count' : 1})\n",
    "                \n",
    "                \n",
    "    # Return output\n",
    "    return output          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The common spelling errors among the whole data set is\n",
      "sta ['star', 'star', 'staff', 'staff']\n",
      "yor ['your', 'your', 'your', 'your']\n",
      "the ['they', 'they', 'they', 'they']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH91nDeSt8NrxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c3dab8f9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n"
     ]
    }
   ],
   "source": [
    "def sub(str1,str2): \n",
    "    seqMatch = SequenceMatcher(None,str1,str2) \n",
    "    match = seqMatch.find_longest_match(0, len(str1), 0, len(str2)) \n",
    "    if (match.size!=0):\n",
    "        z=str1[match.a: match.a + match.size]\n",
    "        return z\n",
    "    \n",
    "def de(str1,str2,str3):\n",
    "    a=dict()\n",
    "    c=None\n",
    "    for i in str1:\n",
    "        for j in str2:\n",
    "            if(i==j and str1.index(i)==str2.index(j)):\n",
    "                c=str1.replace(i,'')\n",
    "            \n",
    "                \n",
    "    if c==None:\n",
    "        return\n",
    "    if c not in a.keys():\n",
    "        a[c]=[str1,str3]\n",
    "    else:\n",
    "        a[c]=a[c]+[str1,str3]\n",
    "    return a\n",
    "\t\n",
    "def spel(i):\n",
    "    a=[error['old_text'] for error in data[i]['markup'] if error['type'] == 'spelling']\n",
    "    b=[error['new_text'] for error in data[i]['markup'] if error['type'] == 'spelling']\n",
    "    co=0\n",
    "    e=dict()\n",
    "    for i in range(0,len(a)-1):\n",
    "        for j in range(i,len(a)-1):\n",
    "            if i!=j:\n",
    "                c=sub(a[i],a[j])\n",
    "                if(c!=None and len(c)>3 and b[j]!=None):\n",
    "                    d=de(a[j],b[j],a[i])\n",
    "                    if(d is not None):\n",
    "                        for k in d.keys():\n",
    "                            e[k]=d[k]\n",
    "    if e!=None:\n",
    "        r1=0\n",
    "        g=dict()\n",
    "        for i in e.keys():\n",
    "            if len(e[i])>1:\n",
    "                g[i]=len(e[i])\n",
    "                r1=r1+len(e[i])\n",
    "\n",
    "        #print(\"common error patterns\",end=' ')\n",
    "        #print([i for i in e.keys() if len(e[i])>1])\n",
    "        #print(\"common error words\", end=' ')\n",
    "        #print([v for v in e.values() if len(e[i])>1] )\n",
    "\n",
    "\n",
    "        #print(\"percentage of common errors:\",end=' ')\n",
    "        #if(len(a)!=0):\n",
    "         #   print((r1*100)/len(a))\n",
    "        #else:\n",
    "         #   print(\"No spelling errors found\")\n",
    "\n",
    "        #plt.bar(g.keys(), g.values(), 1, color='g')\n",
    "        #plt.show()\n",
    "        return e\n",
    "def act():\n",
    "    f=dict()\n",
    "    m,k=0,0\n",
    "    for i in range(0,209):\n",
    "        e=spel(i)\n",
    "        if e is not None:\n",
    "            for i in e.keys():\n",
    "                if i not in f.keys():\n",
    "                    f[i]=e[i]\n",
    "                    k=k+len(e[i])\n",
    "                else:\n",
    "                    f[i]=f[i]+e[i]\n",
    "                    k=k+len(e[i])\n",
    "                    \n",
    "    c=[(len(f[i]),i) for i in f.keys() if len(f[i])>2]\n",
    "    print(\"The common spelling errors among the whole data set is\")\n",
    "    h=dict()\n",
    "    for i in c:\n",
    "        h[i[1]]=len(f[i[1]])\n",
    "        print(i[1],f[i[1]])\n",
    "    plt.bar(h.keys(),h.values(),1, color='b')\n",
    "    plt.show()\n",
    "    return k\n",
    "\n",
    "print(act())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_choice_test = {'plaintext' : 'aaaaa', 'markup' : [{'start_index': 6,\n",
    "                      'end_index': 11,\n",
    "                      'old_text': 'dad',\n",
    "                      'new_text': 'father',\n",
    "                      'type': 'word choice',\n",
    "                      'comment': ''}, \n",
    "                      {'start_index': 10,\n",
    "                      'end_index': 11,\n",
    "                      'old_text': 'dady',\n",
    "                      'new_text': 'father',\n",
    "                      'type': 'word choice',\n",
    "                      'comment': ''},\n",
    "                      {'start_index': 20,\n",
    "                      'end_index': 25,\n",
    "                      'old_text': 'mom',\n",
    "                      'new_text': 'mother',\n",
    "                      'type': 'word choice',\n",
    "                      'comment': ''}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ck.word_choice(word_choice_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running word_choice checking similar error on grade 4 essay dataset to check if student offen repeat word_choice error in an essay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wc_freq = [wc_error['error_count'] for essay in data for wc_error in ck.word_choice(essay)]\n",
    "wc_freq_dict = nltk.FreqDist(wc_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wc_freq_dict.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wc_freq_dict.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Total number repeated error\n",
    "wc_repeated_cnt = sum([1 for cnt in wc_freq if cnt > 1])\n",
    "\n",
    "# Total number of different word_choice error\n",
    "wc_total = sum(wc_freq)\n",
    "\n",
    "# In total all the word_choice error, the pecent of error appear more than 1 in an essay\n",
    "(wc_repeated_cnt * 100.0) / wc_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the most common word choice error that all student made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tuple of set of word of word choice error and its appearance\n",
    "word_set_freq = [[wc_error['words'], wc_error['error_count']] for essay in data for wc_error in ck.word_choice(essay)]\n",
    "word_set_freq_merge = []\n",
    "rm_index_set = set()\n",
    "for i in range(len(word_set_freq)):\n",
    "    if i not in rm_index_set:\n",
    "        c = word_set_freq[i]\n",
    "        for j in range(i+1, len(word_set_freq)):\n",
    "            if j not in rm_index_set:\n",
    "                tmp = word_set_freq[j]\n",
    "                for w in tmp[0]:\n",
    "                    if w in c[0]:\n",
    "                        c[1] = c[1] + tmp[1]\n",
    "                        rm_index_set.add(j)\n",
    "                        break        \n",
    "        word_set_freq_merge.append(c)\n",
    "        \n",
    "word_set_freq_dict =  nltk.FreqDist([', '.join(err[0]) for err in word_set_freq_merge for i in range(err[1])])     \n",
    "word_set_freq_dict.most_common(10)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuation Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "puct_error = [error for essay in data for error in essay['markup'] if error['type'] == 'punctuation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(puct_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "puct_error[:2]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Define a set of rules for similar punctuation errors\n",
    "# The rules we set bases on the markup punctuation error from essay input above\n",
    "# return a dictionary of all similar errors and numbers of their appearance\n",
    "def punctuation_error(input):\n",
    "    output = {}\n",
    "    # Loop through all errors in an essay then process only punctuation error\n",
    "    for i in range(len(input['markup'])):\n",
    "        error = input['markup'][i]\n",
    "        if (error['type'] == 'punctuation'):  \n",
    "            old_text = error['old_text']\n",
    "            new_text = error['new_text']\n",
    "            if new_text != None:\n",
    "                new_text_trim = new_text.replace(' ', '')\n",
    "            old_text_trim = old_text.replace(' ', '')\n",
    "            \n",
    "            #if old_text == new_text:\n",
    "                #raise ValueError(\"Markup error new and old text are the same\")\n",
    "            # Capitalization error: text on old and new word are the same except capilize a character\n",
    "            if(new_text != None and old_text.lower() == new_text.lower()):\n",
    "                # check if we already had capitalization error on output\n",
    "                # Add new if there is not\n",
    "                if('capitalization_error' not in output):\n",
    "                    output['capitalization_error'] = {'definition' : 'Errors on capitalization',\n",
    "                                                       'index' : [i], 'error_count' : 1}\n",
    "                else:\n",
    "                    output['capitalization_error']['index'].append(i)\n",
    "                    error_cnt = output['capitalization_error']['error_count']\n",
    "                    output['capitalization_error']['error_count'] = error_cnt + 1\n",
    "            \n",
    "            # Error of misleading between 2 punctuations\n",
    "            elif( new_text != None and  old_text != None \n",
    "               and len(old_text) == 1 and  len(new_text) == 1 \n",
    "               and old_text in string.punctuation  and new_text in string.punctuation):\n",
    "                error_name = ''\n",
    "                if((('misleading ' + old_text + new_text) in output)):\n",
    "                    error_name = 'misleading ' + old_text + new_text\n",
    "                elif ((('misleading ' + new_text + old_text) in output)):\n",
    "                    error_name = 'misleading ' + new_text + old_text\n",
    "                \n",
    "                # check if output has this type of error - add new if not\n",
    "                if(error_name == ''):\n",
    "                    error_name = 'misleading ' + old_text + new_text\n",
    "                    error_def = 'Errors of misleading between ' + old_text + ' and ' + new_text\n",
    "                    output[error_name] = {'definition' : error_def, 'index' : [i], 'error_count' : 1}\n",
    "                else:\n",
    "                    output[error_name]['index'].append(i)\n",
    "                    output[error_name]['error_count'] = output[error_name]['error_count'] + 1\n",
    "               \n",
    "            # Error of using wrong a punctuation or missing using an punctuation\n",
    "                # First case: new_word/old_word contain empty string and/or a punctuation\n",
    "            elif(new_text !=  None and ((old_text_trim == '' and len(new_text_trim) == 1 \n",
    "                  and new_text_trim in string.punctuation) or ((new_text_trim == '') \n",
    "                 and len(old_text_trim) == 1 and old_text_trim in string.punctuation))):\n",
    "                error_name = 'error_use ' + old_text_trim + new_text_trim\n",
    "                # check if output has this type of error - add new if not\n",
    "                if(error_name not in output):\n",
    "                    error_def = 'Wrong used or missing using of ' + old_text_trim + new_text_trim\n",
    "                    output[error_name] = {'definition' : error_def, 'index' : [i], 'error_count' : 1}\n",
    "                else:\n",
    "                    output[error_name]['index'].append(i)\n",
    "                    output[error_name]['error_count'] = output[error_name]['error_count'] + 1\n",
    "                # Second case: new_word/old_word contains a sentence with a punctuation \n",
    "                # and the other contain the same sentence without that punctuation\n",
    "            elif(new_text !=  None and abs(len(old_text_trim) - len(new_text_trim)) == 1):\n",
    "                # Get the different character between old_word and new_word\n",
    "                # Then check if the different character between them is punctuation or not\n",
    "                if(len(old_text_trim) > len(new_text_trim)):\n",
    "                    dif_char = list(Counter(old_text_trim.lower()) - Counter(new_text_trim.lower()))[0]\n",
    "                else:\n",
    "                    dif_char = list(Counter(new_text_trim.lower()) - Counter(old_text_trim.lower()))[0]\n",
    "                    \n",
    "                if(dif_char in string.punctuation):\n",
    "                    error_name = 'error_use ' + dif_char\n",
    "                    if(error_name not in output):\n",
    "                        error_def = 'Wrong used or missing using of ' + dif_char\n",
    "                        output[error_name] = {'definition' : error_def, 'index' : [i], 'error_count' : 1}\n",
    "                    else:\n",
    "                        output[error_name]['index'].append(i)\n",
    "                        output[error_name]['error_count'] = output[error_name]['error_count'] + 1\n",
    "                # Otherwise add to other error\n",
    "                else:\n",
    "                    error_name = 'other_error'\n",
    "                    if(error_name not in output):\n",
    "                        output[error_name] = {'definition' : 'other errors', 'index' : [i], 'error_count' : 1}\n",
    "                    else:\n",
    "                        output[error_name]['index'].append(i)\n",
    "                        output[error_name]['error_count'] = output[error_name]['error_count'] + 1\n",
    "             \n",
    "            # The rest add to other error\n",
    "            else:\n",
    "                error_name = 'other_error'\n",
    "                if(error_name not in output):\n",
    "                    output[error_name] = {'definition' : 'other errors', 'index' : [i], 'error_count' : 1}\n",
    "                else:\n",
    "                    output[error_name]['index'].append(i)\n",
    "                    output[error_name]['error_count'] = output[error_name]['error_count'] + 1\n",
    "    return output\n",
    "                    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test run on a custom input and on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "punctuation_test = {'plaintext' : 'aaaaa', 'markup' : [\n",
    "                    {'start_index': 1824,\n",
    "                  'end_index': 1825,\n",
    "                  'old_text': '',\n",
    "                  'new_text': '.',\n",
    "                  'type': 'punctuation',\n",
    "                  'comment': ''}, \n",
    "                    {'start_index': 138,\n",
    "                   'end_index': 139,\n",
    "                   'old_text': '.',\n",
    "                   'new_text': '?',\n",
    "                   'type': 'punctuation',\n",
    "                   'comment': ''},\n",
    "                      {'start_index': 235,\n",
    "                  'end_index': 236,\n",
    "                  'old_text': '',\n",
    "                  'new_text': ',',\n",
    "                  'type': 'punctuation',\n",
    "                  'comment': ''},\n",
    "                    {'start_index': 400,\n",
    "                  'end_index': 401,\n",
    "                  'old_text': 't',\n",
    "                  'new_text': 'T',\n",
    "                  'type': 'punctuation',\n",
    "                  'comment': ''},\n",
    "                    {'start_index': 592,\n",
    "                  'end_index': 594,\n",
    "                  'old_text': 'f',\n",
    "                  'new_text': '.  F',\n",
    "                  'type': 'punctuation',\n",
    "                  'comment': ''},\n",
    "                 {'start_index': 620,\n",
    "                  'end_index': 621,\n",
    "                  'old_text': 'w',\n",
    "                  'new_text': 'W',\n",
    "                  'type': 'punctuation',\n",
    "                  'comment': ''},\n",
    "                    {'start_index': 67,\n",
    "                  'end_index': 78,\n",
    "                  'old_text': 'is surprise',\n",
    "                  'new_text': 'is, surprise',\n",
    "                  'type': 'punctuation',\n",
    "                  'comment': ''},\n",
    "                 {'start_index': 398,\n",
    "                  'end_index': 406,\n",
    "                  'old_text': 'is three',\n",
    "                  'new_text': 'is, three',\n",
    "                  'type': 'punctuation',\n",
    "                  'comment': ''},\n",
    "                    {'start_index': 407,\n",
    "                  'end_index': 421,\n",
    "                  'old_text': \"strikes you're\",\n",
    "                  'new_text': \"strikes, you're\",\n",
    "                  'type': 'punctuation',\n",
    "                  'comment': ''},\n",
    "                    {'start_index': 977,\n",
    "                  'end_index': 978,\n",
    "                  'old_text': 'I',\n",
    "                  'new_text': None,\n",
    "                  'type': 'punctuation',\n",
    "                  'comment': ''},\n",
    "                    {'start_index': 977,\n",
    "                  'end_index': 978,\n",
    "                  'old_text': 'w',\n",
    "                  'new_text': 'Well',\n",
    "                  'type': 'punctuation',\n",
    "                  'comment': ''},\n",
    "            ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ck.punctuation_error(data[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[9]['markup']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ck.punctuation_error(punctuation_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make sure that total error we count equal total of punctuation error in input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert(len([k for k in punctuation_test['markup'] if k['type'] == 'punctuation']) == \n",
    "       sum(error['error_count'] for error in ck.punctuation_error(punctuation_test).values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for essay in data:\n",
    "    assert(len([p for p in essay['markup'] if p['type'] == 'punctuation']) == \n",
    "           sum(error['error_count'] for error in ck.punctuation_error(essay).values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some Stat for counting punctuation error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Total Number of punctuation errors were marked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_punc_error = len([error for essay in data \n",
    "                        for error in essay['markup'] \n",
    "                        if error['type'] == 'punctuation'])\n",
    "total_punc_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Total Number of punctuation errors that we can classify (Not put on other_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctb_punc_error = sum([error[1]['error_count'] for essay in data \n",
    "                      for error in ck.punctuation_error(essay).items() \n",
    "                      if error[0] != 'other_error'])\n",
    "ctb_punc_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Percent of punctuation error that we can classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Punc_classify_rate = (ctb_punc_error * 100.0) / total_punc_error\n",
    "Punc_classify_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Distribution of the repeatable of a type of error in an essay\n",
    "We want to check how frequently a student make the same punctuation error in an essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A list of number of each type of punctuation error in an essay for the whole dataset\n",
    "repeat_error_cnt = [error[1]['error_count'] for essay in data \n",
    "                      for error in ck.punctuation_error(essay).items() \n",
    "                      if error[0] != 'other_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_cnt_freq = nltk.FreqDist(repeat_error_cnt)\n",
    "error_cnt_freq.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_cnt_freq.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of repeated error\n",
    "punc_repeated_cnt = sum([num for num in repeat_error_cnt if num > 1])\n",
    "\n",
    "# Percent of repeated punctuation error \n",
    "punc_repeated_cnt/total_punc_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we want to find for all student in grade 4, which punctuation errors that they usually make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List of All punc_error in all essays after classify\n",
    "punc_errors = [error for essay in data \n",
    "                      for error in ck.punctuation_error(essay).items() \n",
    "                      if error[0] != 'other_error']\n",
    "\n",
    "# All different error types\n",
    "punc_error_type = set([p_type[0] for p_type in punc_errors])\n",
    "punc_error_type\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Each type with total number of appearance\n",
    "error_cnt_total = {key : sum([error[1]['error_count'] \n",
    "                              for error in punc_errors if error[0] == key]) \n",
    "                   for key in punc_error_type} \n",
    "\n",
    "error_cnt_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# There still dublicated in the ressult like 'misleading ,?' and 'misleading ?,'\n",
    "# We're going to merge them\n",
    "error_cnt_total_fix = error_cnt_total.copy()\n",
    "for k in error_cnt_total:\n",
    "    if(k[:10] == 'misleading' and k in error_cnt_total_fix):\n",
    "        deleted_key = 'misleading ' + k[12] + k[11]\n",
    "        if deleted_key in error_cnt_total_fix:\n",
    "            error_cnt_total_fix[k] = error_cnt_total_fix[k] + error_cnt_total_fix[deleted_key]\n",
    "            del error_cnt_total_fix[deleted_key]\n",
    "error_cnt_total_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_cnt_total_dict = nltk.FreqDist(error_cnt_total_fix)\n",
    "error_cnt_total_dict.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "error_cnt_total_dict.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=dict()\n",
    "for i in range(0,209):\n",
    "    if e is not None:\n",
    "        for i in e.keys():\n",
    "            if i not in f.keys():\n",
    "                f[i]=e[i]\n",
    "            else:\n",
    "                f[i]=f[i]+e[i]\n",
    "c=[(len(f[i]),i) for i in f.keys() if len(f[i])>2]\n",
    "print(f)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent of error can be classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Total of Error\n",
    "total_error = len([error for essay in data \n",
    "                        for error in essay['markup']])\n",
    "total_error\n",
    "\n",
    "# Total Error can classify\n",
    "total_err_classify = ctb_punc_error + wc_total # + Spelling\n",
    "\n",
    "# Percent of errors can classify\n",
    "total_err_classify * 100.0 / total_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent of error is duplicated in an essay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of dublicated error (appearing more than 2 in an essay)\n",
    "dub_cnt = punc_repeated_cnt + wc_repeated_cnt # + Spelling\n",
    "\n",
    "# percentage\n",
    "dub_cnt / total_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The common spelling errors among the whole data set is\n",
      "sta ['star', 'star', 'staff', 'staff']\n",
      "yor ['your', 'your', 'your', 'your']\n",
      "the ['they', 'they', 'they', 'they']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAD7NJREFUeJzt3X+s3XV9x/Hny1Kjm27N0hup/UHJ\n0mQRN4VdK8Rl6YxboCPjj7GJiRL5pwExkcTFOP+AmG3ZlhnjEEPTKVGi0Tl/kIaUOLLBBDfA21oq\nFdk658YNnVxwFCtEV3zvj/P94+70lPO9957bUz59PpJv7vfH+3zPOz09r/u53/P9nm+qCklSW142\n7QYkSZNnuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIadM60nnj9+vW1devWaT29\nJL0k7d+//6mqmhlXN7Vw37p1K3Nzc9N6ekl6SUryn33qPCwjSQ0y3CWpQYa7JDXIcJekBhnuktSg\n3uGeZE2SbyW5c8S2JLk5yZEkh5JcNNk2JUlLsZSR+/uAR0+x7TJgWzftAm5dYV+SpBXoFe5JNgG/\nC3zyFCVXALfXwAPAuiQbJtSjJGmJ+o7cPwZ8APjZKbZvBB5ftDzfrZMkTcHYK1STXA48WVX7k+w4\nVdmIdSfdeTvJLgaHbdiyZcsS2hzez7IfKklTVyel4+T1Gbm/Bfi9JN8HvgC8Nclnh2rmgc2LljcB\nTwzvqKr2VNVsVc3OzIz9agRJ0jKNDfeq+uOq2lRVW4GrgH+sqncOle0Fru7OmrkYOFZVRyffriSp\nj2V/cViSawGqajewD9gJHAGeA66ZSHeSpGVZUrhX1b3Avd387kXrC7h+ko1JkpbPK1QlqUGGuyQ1\nyHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMM\nd0lqkOEuSQ0y3CWpQWPDPckrkjyU5OEkh5N8eETNjiTHkhzsphtXp11JUh99brP3E+CtVXU8yVrg\n/iR3VdUDQ3X3VdXlk29RkrRUY8O9uz/q8W5xbTfVajYlSVqZXsfck6xJchB4Eri7qh4cUXZJd+jm\nriQXTLRLSdKS9Ar3qnqhqt4IbAK2J3n9UMkB4LyqegPwceCOUftJsivJXJK5hYWFlfQtSXoRSzpb\npqqeAe4FLh1a/2xVHe/m9wFrk6wf8fg9VTVbVbMzMzPL71qS9KL6nC0zk2RdN/9K4G3Ad4dqzk2S\nbn57t9+nJ9+uJKmPPmfLbAA+k2QNg9D+YlXdmeRagKraDVwJXJfkBPA8cFX3QawkaQr6nC1zCLhw\nxPrdi+ZvAW6ZbGuSpOXyClVJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpkuEtSgwx3SWqQ\n4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqUJ97qL4iyUNJHk5yOMmHR9Qkyc1J\njiQ5lOSi1WlXktRHn3uo/gR4a1UdT7IWuD/JXVX1wKKay4Bt3fRm4NbupyRpCsaO3GvgeLe4tpuG\nb359BXB7V/sAsC7Jhsm2Kknqq9cx9yRrkhwEngTurqoHh0o2Ao8vWp7v1g3vZ1eSuSRzCwsLy+1Z\nkjRGr3Cvqheq6o3AJmB7ktcPlWTUw0bsZ09VzVbV7MzMzNK7lST1sqSzZarqGeBe4NKhTfPA5kXL\nm4AnVtSZJGnZ+pwtM5NkXTf/SuBtwHeHyvYCV3dnzVwMHKuqoxPvVpLUS5+zZTYAn0myhsEvgy9W\n1Z1JrgWoqt3APmAncAR4DrhmlfqVJPUwNtyr6hBw4Yj1uxfNF3D9ZFuTJC2XV6hKUoMMd0lqkOEu\nSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLU\nIMNdkhpkuEtSg/rcQ3VzknuSPJrkcJL3jajZkeRYkoPddOPqtCtJ6qPPPVRPAO+vqgNJXg3sT3J3\nVX1nqO6+qrp88i1KkpZq7Mi9qo5W1YFu/kfAo8DG1W5MkrR8SzrmnmQrg5tlPzhi8yVJHk5yV5IL\nTvH4XUnmkswtLCwsuVlJUj+9wz3Jq4AvAzdU1bNDmw8A51XVG4CPA3eM2kdV7amq2aqanZmZWW7P\nkqQxeoV7krUMgv1zVfWV4e1V9WxVHe/m9wFrk6yfaKeSpN76nC0T4FPAo1X10VPUnNvVkWR7t9+n\nJ9moJKm/PmfLvAV4F/DtJAe7dR8CtgBU1W7gSuC6JCeA54GrqqpWoV9JUg9jw72q7gcypuYW4JZJ\nNSVJWhmvUJWkBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpk\nuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QG9bmH6uYk9yR5NMnhJO8bUZMkNyc5kuRQkotWp11J\nUh997qF6Anh/VR1I8mpgf5K7q+o7i2ouA7Z105uBW7ufkqQpGDtyr6qjVXWgm/8R8CiwcajsCuD2\nGngAWJdkw8S7lST1sqRj7km2AhcCDw5t2gg8vmh5npN/AZBkV5K5JHMLCwtL61SS1FvvcE/yKuDL\nwA1V9ezw5hEPqZNWVO2pqtmqmp2ZmVlap5Kk3nqFe5K1DIL9c1X1lREl88DmRcubgCdW3p4kaTn6\nnC0T4FPAo1X10VOU7QWu7s6auRg4VlVHJ9inJGkJ+pwt8xbgXcC3kxzs1n0I2AJQVbuBfcBO4Ajw\nHHDN5FuVJPU1Ntyr6n5GH1NfXFPA9ZNqSpK0Ml6hKkkNMtwlqUGGuyQ1yHCXpAYZ7pLUIMNdkhpk\nuEtSgwx3SWqQ4S5JDTLcJalBhrskNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqUJ/b7N2W5Mkkj5xi\n+44kx5Ic7KYbJ9+mJGkp+txm79PALcDtL1JzX1VdPpGOJEkrNnbkXlVfB354GnqRJE3IpI65X5Lk\n4SR3JblgQvuUJC1Tn8My4xwAzquq40l2AncA20YVJtkF7ALYsmXLBJ5akjTKikfuVfVsVR3v5vcB\na5OsP0XtnqqararZmZmZlT61JOkUVhzuSc5Nkm5+e7fPp1e6X0nS8o09LJPk88AOYH2SeeAmYC1A\nVe0GrgSuS3ICeB64qqpq1TqWJI01Ntyr6h1jtt/C4FRJSdIZwitUJalBhrskNchwl6QGGe6S1CDD\nXZIaZLhLUoMMd0lqkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwl\nqUFjwz3JbUmeTPLIKbYnyc1JjiQ5lOSiybcpSVqKPiP3TwOXvsj2y4Bt3bQLuHXlbUmSVmJsuFfV\n14EfvkjJFcDtNfAAsC7Jhkk1KElaukkcc98IPL5oeb5bJ0makkmEe0asq5GFya4kc0nmFhYWJvDU\nkqRRJhHu88DmRcubgCdGFVbVnqqararZmZmZCTy1JGmUSYT7XuDq7qyZi4FjVXV0AvuVJC3TOeMK\nknwe2AGsTzIP3ASsBaiq3cA+YCdwBHgOuGa1mpUk9TM23KvqHWO2F3D9xDqSJK2YV6hKUoMMd0lq\nkOEuSQ0y3CWpQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAYZ\n7pLUIMNdkhpkuEtSg3qFe5JLkzyW5EiSD47YviPJsSQHu+nGybcqSeqrzz1U1wCfAH4bmAe+mWRv\nVX1nqPS+qrp8FXqUJC1Rn5H7duBIVX2vqn4KfAG4YnXbkiStRJ9w3wg8vmh5vls37JIkDye5K8kF\nE+lOkrQsYw/LABmxroaWDwDnVdXxJDuBO4BtJ+0o2QXsAtiyZcsSW5Uk9dVn5D4PbF60vAl4YnFB\nVT1bVce7+X3A2iTrh3dUVXuqaraqZmdmZlbQtiTpxfQJ928C25Kcn+TlwFXA3sUFSc5Nkm5+e7ff\npyfdrCSpn7GHZarqRJL3Al8D1gC3VdXhJNd223cDVwLXJTkBPA9cVVXDh24kSadJppXBs7OzNTc3\nt6zHZtSnAJL0ErGS2E2yv6pmx9V5haokNchwl6QGGe6S1CDDXZIaZLhLUoMMd0lqkOEuSQ0y3CWp\nQYa7JDXIcJekBhnuktQgw12SGmS4S1KDDHdJapDhLkkNMtwlqUGGuyQ1qFe4J7k0yWNJjiT54Ijt\nSXJzt/1Qkosm36okqa+x4Z5kDfAJ4DLgdcA7krxuqOwyYFs37QJunXCfkqQl6DNy3w4cqarvVdVP\ngS8AVwzVXAHcXgMPAOuSbJhwr5KknvqE+0bg8UXL8926pdZIkk6Tc3rUZMS64Xt396khyS4Gh20A\njid5rMfzt2498NS0m9BJfF3OPM28JhmVmP2d16eoT7jPA5sXLW8CnlhGDVW1B9jTp7GzRZK5qpqd\ndh/6/3xdzjy+JkvT57DMN4FtSc5P8nLgKmDvUM1e4OrurJmLgWNVdXTCvUqSeho7cq+qE0neC3wN\nWAPcVlWHk1zbbd8N7AN2AkeA54BrVq9lSdI4qTrp0LhOoyS7usNVOoP4upx5fE2WxnCXpAb59QOS\n1CDDfUqS3JDk56bdx9kqybok7+nmdyS5c9o9SZNkuE/PDYDhPj3rgPdMuwmtXPcVKRrS5zx3rVCS\nnwe+yOD8/zXA3wGvBe5J8lRV/VaSW4E3Aa8EvlRVN02t4bPDXwC/nOQg8L/Aj5N8CXg9sB94Z1VV\nkl8HPgq8isEFNO/2NN/VkeRPgKeq6q+75T8DnmTwvrmMwYWRf1pVf5tkB3ATcBR4I4PvvdJiVeW0\nyhPw+8DfLFr+ReD7wPpF636p+7kGuBf4tWn33fIEbAUe6eZ3AMcYhMjLgH8BfgNYC/wzMNPVvZ3B\nqcBT77/FqXtNDnTzLwP+vXvv3N29L14D/BewoXvNfgycP+2+z9TJkfvp8W3gI0n+Erizqu7Lydcf\n/2H39QznMPjP+zrg0Olt86z2UFXNA3Sj+a3AMwxG8nd3r9caBiNFrYKq+n6Sp5NcyCDIv8Xgl+zn\nq+oF4AdJ/onBX7jPMnjN/mN6HZ/ZDPfToKr+tfvzfifw50n+fvH2JOcDfwS8qar+J8mngVec/k7P\naj9ZNP8Cg/dGgMNVdcl0WjorfRJ4N3AucBvwOy9S++PT0dBLlR+ongZJXgs8V1WfBT4CXAT8CHh1\nV/ILDP6jHkvyGgbHF7W6Fv/7n8pjwEySSwCSrE1ywap3dnb7KnApg9H514CvA29PsibJDPCbwENT\n7O8lw5H76fGrwF8l+RmDD++uAy4B7kpytAYfqH4LOAx8D/jG9Fo9O1TV00m+keQR4HngByNqfprk\nSuDmJL/I4P3yMQavk1ZB929+D/BMVb2Q5KsM3isPM/hA9QNV9d9JfmWqjb4EeIWqpDNGkpcBB4A/\nqKp/m3Y/L2UelpF0Ruhu33kE+AeDfeUcuUtSgxy5S1KDDHdJapDhLkkNMtwlqUGGuyQ1yHCXpAb9\nH91nDeSt8NrxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c3da4bca20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Spelling errors similar\n",
      "15.637860082304528\n"
     ]
    }
   ],
   "source": [
    "a=0\n",
    "g=act()\n",
    "for i in range(0,209):\n",
    "    a=a+len([error['old_text'] for error in data[i]['markup'] if error['type'] == 'spelling'])\n",
    "print(\"Percentage of Spelling errors similar\")\n",
    "if g!=0:\n",
    "    print(g*100/a)\n",
    "else:\n",
    "    print(\"No spelling errors found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
